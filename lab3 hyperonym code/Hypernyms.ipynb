{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:56:22.948195Z",
     "start_time": "2020-02-12T17:56:22.944176Z"
    }
   },
   "source": [
    "### Lab 2: Hyponyms and Hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.470920Z",
     "start_time": "2020-02-12T14:12:15.640262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import wikipedia\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual,widgets\n",
    "from IPython.display import display\n",
    "import json\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)\n",
    "wikipedia.set_lang(\"ru\")\n",
    "# DATA_PATH_LIST = ['D:','src2','taxonomy-enrichment','data','training_data']\n",
    "DATA_PATH_LIST = ['.']\n",
    "EMBEDDING_MODEL_FILENAME = \"wiki_node2vec.bin\"\n",
    "DATA_PATH=\"/\".join(DATA_PATH_LIST+[\"training_nouns.tsv\"])\n",
    "df = pd.read_csv(DATA_PATH,sep='\\t')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.475780Z",
     "start_time": "2020-02-12T14:12:16.473114Z"
    }
   },
   "outputs": [],
   "source": [
    "def prestr(x):\n",
    "    return str(x).replace('\\\"','').replace(\"'\",'\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.685506Z",
     "start_time": "2020-02-12T14:12:16.477634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4177778701654e3eb5f8ed7e1338d2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Draw', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a301e7a689a459e8dead918dfa7dd7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='МАТЬ', description='String:', placeholder='Query')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button = widgets.Button(description=\"Draw\")\n",
    "query = widgets.Text(\n",
    "    value='МАТЬ',\n",
    "    placeholder='Query',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")\n",
    "display(button,query)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def creategraph(df):\n",
    "    res = []\n",
    "    for row in df.values:\n",
    "        cohyps = row[1].split(\",\")\n",
    "        for idx,cohyp in enumerate(cohyps):\n",
    "            for parent in json.loads(prestr(row[2])):\n",
    "                res.append((row[0]+'-'+str(idx),parent))\n",
    "    return res\n",
    "\n",
    "def graphdraw(b):\n",
    "    print(\"graphdraw\",query.value)\n",
    "    subset = df[df['TEXT'].str.contains(query.value.upper())]\n",
    "    g = nx.DiGraph()\n",
    "    for el in subset.values:\n",
    "        cohyps = el[1].split(\",\")\n",
    "        print(cohyps)\n",
    "        syns = idx2syns[el[0]]\n",
    "        for child in cohyps:\n",
    "            for parent in json.loads(prestr(el[2])):\n",
    "                ed = g.add_edge(child,idx2syns[parent],label=\"is a\")\n",
    "            \n",
    "    plt.figure(figsize=(15,15))\n",
    "    pos = nx.nx_agraph.graphviz_layout(g)\n",
    "    nx.draw(g,with_labels=True,pos=pos)\n",
    "#     edge_labels=nx.draw_networkx_edge_labels(g,pos=pos)\n",
    "    plt.show()\n",
    "button.on_click(graphdraw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:12:34.060220Z",
     "start_time": "2020-02-12T17:12:34.055235Z"
    }
   },
   "source": [
    "### Interactive visualization of hyponyms and hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:11:37.966489Z",
     "start_time": "2020-02-12T17:11:37.931688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0520d0a399424e4a8fb68b14f25969b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Draw', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e6105e94664df3abc0357d0862ee9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='МАТЬ', description='String:', placeholder='Query')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button = widgets.Button(description=\"Draw\")\n",
    "query = widgets.Text(\n",
    "    value='МАТЬ',\n",
    "    placeholder='Query',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")\n",
    "display(button,query)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def creategraph(df):\n",
    "    res = []\n",
    "    for row in df.values:\n",
    "        cohyps = row[1].split(\",\")\n",
    "        for idx,cohyp in enumerate(cohyps):\n",
    "            for parent in json.loads(prestr(row[2])):\n",
    "                res.append((row[0]+'-'+str(idx),parent))\n",
    "    return res\n",
    "\n",
    "def graphdraw(b):\n",
    "    print(\"graphdraw\",query.value)\n",
    "    subset = df[df['TEXT'].str.contains(query.value.upper())]\n",
    "    g = nx.DiGraph()\n",
    "    for el in subset.values:\n",
    "        cohyps = el[1].split(\",\")\n",
    "        print(cohyps)\n",
    "        syns = idx2syns[el[0]]\n",
    "        for child in cohyps:\n",
    "            for parent in json.loads(prestr(el[2])):\n",
    "                ed = g.add_edge(child,idx2syns[parent],label=\"is a\")\n",
    "            \n",
    "    plt.figure(figsize=(15,15))\n",
    "    pos = nx.nx_agraph.graphviz_layout(g)\n",
    "    nx.draw(g,with_labels=True,pos=pos)\n",
    "#     edge_labels=nx.draw_networkx_edge_labels(g,pos=pos)\n",
    "    plt.show()\n",
    "button.on_click(graphdraw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T11:38:20.619158Z",
     "start_time": "2020-02-12T11:38:20.614734Z"
    }
   },
   "source": [
    "### Pattern extractor\n",
    "\n",
    "Yargy — библиотека для извлечения структурированной информации из текстов на русском языке. Правила описываются контекстно-свободными грамматиками и словарями ключевых слов. Банк готовых правил для имён, дат, адресов и других сущностей доступен в репозитории Natasha.\n",
    "* https://yargy.readthedocs.io/ru/latest/\n",
    "* http://pymorphy2.readthedocs.io/en/latest/user/grammemes.html\n",
    "* https://github.com/natasha/natasha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-12T13:09:50.486Z"
    }
   },
   "source": [
    "### Токенизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.819980Z",
     "start_time": "2020-02-12T14:12:16.708109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ростов', '-', 'на', '-', 'Дону']\n",
      "['Длительностью', '18', 'ч', '.', '10', 'мин', '.']\n",
      "['Яндекс', '.', 'Такси']\n",
      "['π', '≈', '3', '.', '1415']\n",
      "['1', '500', '000', '$']\n",
      "['http', ':', '/', '/', 'vk', '.', 'com']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from yargy.tokenizer import MorphTokenizer\n",
    "\n",
    "\n",
    "tokenizer = MorphTokenizer()\n",
    "text = '''Ростов-на-Дону\n",
    "Длительностью 18ч. 10мин.\n",
    "Яндекс.Такси\n",
    "π ≈ 3.1415\n",
    "1 500 000$\n",
    "http://vk.com\n",
    "'''\n",
    "for line in text.splitlines():\n",
    "    print([_.value for _ in tokenizer(line)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:11:56.582467Z",
     "start_time": "2020-02-12T13:11:56.566175Z"
    }
   },
   "source": [
    "# Газеттир\n",
    "Газеттир нужен для удобной работы с последовательностью слов. Например, можно написать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.844412Z",
     "start_time": "2020-02-12T14:12:16.821582Z"
    }
   },
   "outputs": [],
   "source": [
    "from yargy import or_, rule\n",
    "from yargy.predicates import normalized\n",
    "\n",
    "RULE = or_(\n",
    "    rule(normalized('dvd'), '-', normalized('диск')),\n",
    "    rule(normalized('видео'), normalized('файл'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.968622Z",
     "start_time": "2020-02-12T14:12:16.846737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Видео', 'файл']\n",
      "['dvd', '-', 'диске']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from yargy import Parser\n",
    "from yargy.pipelines import morph_pipeline\n",
    "\n",
    "\n",
    "RULE = morph_pipeline([\n",
    "    'dvd-диск',\n",
    "    'видео файл',\n",
    "    'видеофильм',\n",
    "    'газета',\n",
    "    'электронный дневник',\n",
    "    'эссе',\n",
    "])\n",
    "\n",
    "parser = Parser(RULE)\n",
    "text = 'Видео файл на dvd-диске'\n",
    "for match in parser.findall(text):\n",
    "    print([_.value for _ in match.tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:54.576104Z",
     "start_time": "2020-02-12T14:12:54.511149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Чеченской', 'республике']\n",
      "['Донецкая', 'народная', 'республика']\n"
     ]
    }
   ],
   "source": [
    "from yargy import Parser, rule, and_\n",
    "from yargy.predicates import gram, is_capitalized, dictionary\n",
    "\n",
    "\n",
    "GEO = rule(\n",
    "    and_(\n",
    "        gram('ADJF'),  # так помечается прилагательное, остальные пометки описаны в\n",
    "                       # http://pymorphy2.readthedocs.io/en/latest/user/grammemes.html\n",
    "        is_capitalized()\n",
    "    ),\n",
    "    gram('ADJF').optional().repeatable(),\n",
    "    dictionary({\n",
    "        'федерация',\n",
    "        'республика'\n",
    "    })\n",
    ")\n",
    "\n",
    "\n",
    "parser = Parser(GEO)\n",
    "text = '''\n",
    "В Чеченской республике на день рождения ...\n",
    "Донецкая народная республика провозгласила ...\n",
    "Башня Федерация — одна из самых высоких ...\n",
    "'''\n",
    "for match in parser.findall(text):\n",
    "    print([_.value for _ in match.tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:13:57.167613Z",
     "start_time": "2020-02-12T13:13:57.159920Z"
    }
   },
   "source": [
    "### Предикаты\n",
    "\n",
    "Предикат — функция, которая принимает на вход токен и возвращает True или False. В Yargy встроено много готовых предикатов. Полный список есть в справочнике. Предикаты комбинируются с помощью and_, or_ и not_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:17.173350Z",
     "start_time": "2020-02-12T14:12:17.136108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from yargy import and_, not_\n",
    "from yargy.tokenizer import MorphTokenizer\n",
    "from yargy.predicates import is_capitalized, eq\n",
    "\n",
    "\n",
    "tokenizer = MorphTokenizer()\n",
    "token = next(tokenizer('Стали'))\n",
    "\n",
    "predicate = is_capitalized()\n",
    "print(predicate(token))\n",
    "\n",
    "predicate = and_(\n",
    "    is_capitalized(),\n",
    "    not_(eq('марки'))\n",
    ")\n",
    "print(predicate(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:15:56.600763Z",
     "start_time": "2020-02-12T13:15:56.596609Z"
    }
   },
   "source": [
    "### Грамматики\n",
    "В Yargy используется специальный DSL для описания грамматик. Любую контекстно-свободную грамматику можно описать с помощью конструкций Питона. Например, есть примитивная грамматика для размеров одежды:\n",
    "\n",
    "KEY -> р. | размер\n",
    "\n",
    "VALUE -> S | M | L\n",
    "\n",
    "SIZE -> KEY VALUE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:14:21.602988Z",
     "start_time": "2020-02-12T14:14:21.589310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SIZE -> KEY VALUE\n",
       "KEY -> 'р' '.' | 'размер'\n",
       "VALUE -> 'S' | 'M' | 'L' | 'XS'\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yargy import rule, or_\n",
    "\n",
    "\n",
    "KEY = or_(\n",
    "    rule('р', '.'),\n",
    "    rule('размер')\n",
    ").named('KEY')\n",
    "VALUE = or_(\n",
    "    rule('S'),\n",
    "    rule('M'),\n",
    "    rule('L'),\n",
    "    rule('XS'),\n",
    ").named('VALUE')\n",
    "SIZE = rule(\n",
    "    KEY,\n",
    "    VALUE\n",
    ").named('SIZE')\n",
    "SIZE.normalized.as_bnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:14:27.723857Z",
     "start_time": "2020-02-12T14:14:27.662113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['размер', 'M']\n",
      "['размер', 'XS']\n"
     ]
    }
   ],
   "source": [
    "parser = Parser(\n",
    "    SIZE\n",
    ")\n",
    "text = 'размер M; размер A; размер XS;'\n",
    "for match in parser.findall(text):\n",
    "    print([_.value for _ in match.tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:19.308726Z",
     "start_time": "2020-02-12T14:12:17.354354Z"
    }
   },
   "outputs": [],
   "source": [
    "from yargy import Parser, rule, and_, or_, not_\n",
    "from yargy.interpretation import fact, attribute\n",
    "from yargy.predicates import gram, is_capitalized, dictionary, eq\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from gensim import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:19.323139Z",
     "start_time": "2020-02-12T14:12:19.310769Z"
    }
   },
   "outputs": [],
   "source": [
    "START = rule(\n",
    "    or_(\n",
    "        rule(gram('ADJF')),\n",
    "        rule(gram('NOUN'))\n",
    "    ).optional(),\n",
    "    gram('NOUN')\n",
    ")\n",
    "\n",
    "START_S = or_(\n",
    "    eq('такой'),\n",
    "    eq('такие'),\n",
    ")\n",
    "\n",
    "KAK = eq('как')\n",
    "INCLUDING = or_(\n",
    "    or_(\n",
    "        eq('в'),\n",
    "        eq('том'),\n",
    "        eq('числе'),\n",
    "    ),\n",
    "    eq('включающий'),\n",
    "    or_(\n",
    "        eq('включающий'),\n",
    "        eq('в'),\n",
    "        eq('себя'),\n",
    "    ),\n",
    "    or_(\n",
    "        eq('включающие'),\n",
    "        eq('в'),\n",
    "        eq('себя'),\n",
    "    ),\n",
    "    eq('включающие'),\n",
    "    eq('особенно'),\n",
    "\n",
    ")\n",
    "\n",
    "MID_S = or_(\n",
    "    rule(\n",
    "        or_(\n",
    "            eq('такой'),\n",
    "            eq('такие'),\n",
    "        ),\n",
    "        eq('как')\n",
    "    )\n",
    ")\n",
    "ATAKJE = rule(\n",
    "    eq(','),\n",
    "    eq('а'),\n",
    "    eq('также')\n",
    ")\n",
    "\n",
    "MID = or_(\n",
    "    rule(\n",
    "        eq('это')\n",
    "    ),\n",
    "    rule(\n",
    "        eq('—')\n",
    "    ),\n",
    "    rule(\n",
    "        eq('—'),\n",
    "        eq('это')\n",
    "    ),\n",
    "    rule(\n",
    "        eq('—'),\n",
    "        not_(eq('км'))\n",
    "    ),\n",
    "    rule(\n",
    "        or_(\n",
    "            eq('и'),\n",
    "            eq('или'),\n",
    "        ),\n",
    "        eq('другие')\n",
    "    )\n",
    ")\n",
    "\n",
    "END = or_(\n",
    "    rule(\n",
    "        gram('NOUN'),\n",
    "        gram('NOUN')\n",
    "    ),\n",
    "    rule(\n",
    "        gram('ADJF').repeatable(),\n",
    "        gram('NOUN')\n",
    "    ),\n",
    "    rule(\n",
    "        gram('ADJF'),\n",
    "        gram('ADJF').repeatable(),\n",
    "        gram('NOUN')\n",
    "    ),\n",
    "    rule(\n",
    "        gram('NOUN').repeatable(),\n",
    "        gram('ADJF'),\n",
    "        gram('NOUN').repeatable()\n",
    "    ),\n",
    "    rule(\n",
    "        gram('NOUN').repeatable()\n",
    "    )\n",
    ")\n",
    "\n",
    "Item = fact(\n",
    "    'Item',\n",
    "    [attribute('titles').repeatable()]\n",
    ")\n",
    "\n",
    "\n",
    "IGNORE = rule(\n",
    "    '(',\n",
    "    not_(eq(')')).repeatable(),\n",
    "    ')'\n",
    ")\n",
    "\n",
    "ITEM = rule(\n",
    "    IGNORE.interpretation(\n",
    "        Item.titles\n",
    "    ),\n",
    "    eq(',').optional() \n",
    ").repeatable().interpretation(\n",
    "    Item\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:19.434702Z",
     "start_time": "2020-02-12T14:12:19.324707Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_hyperonyms(main_word):\n",
    "    HYPONYM = eq(utils.deaccent(main_word))\n",
    "    RULE = or_(\n",
    "        rule(HYPONYM, ATAKJE, START, MID, END),\n",
    "        rule(HYPONYM, MID, END),\n",
    "        rule(START_S, END, KAK, HYPONYM),\n",
    "        rule(END, INCLUDING, HYPONYM)\n",
    "    )\n",
    "    parser = Parser(RULE) \n",
    "    text = utils.deaccent(wikipedia.summary(main_word))\n",
    "    print(text)\n",
    "    text = re.sub(r'\\(.+?\\)', '', text)\n",
    "    text = text.lower().replace('* сергии радонежскии* ', '')\n",
    "    for idx, match in enumerate(parser.findall(text.lower())):\n",
    "        k = [_.value for _ in match.tokens]\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:22.648500Z",
     "start_time": "2020-02-12T14:12:19.437840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Банан — название съедобных плодов культивируемых растении рода Банан (Musa); обычно под таковыми понимают Musa acuminata и Musa × paradisiaca, а также Musa balbisiana, Musa fehi, Musa troglodytarum и ряд других. Также бананами могут называть плоды Ensete ventricosum (строго говоря, являющегося представителем другого рода семеиства Банановые). С ботаническои точки зрения банан является ягодои, многосеменнои и толстокожеи. У культурных форм часто отсутствуют семена, ненужные при вегетативном размножении. Плоды имеют длину 6—30 см и диаметр 2—5 см. Соплодия могут состоять из 300 плодов и иметь массу до 50—60 кг.\n",
      "Бананы — одна из древнеиших пищевых культур, а для тропических стран важнеишее пищевое растение и главная статья экспорта. Спелые бананы широко употребляются в пищу по всему миру, их используют при приготовлении большого количества блюд. Помимо употребления в свежем виде, в кухне некоторых народов бананы могут зажариваться, или вариться как в очищенном, так и в неочищенном виде. Их также сушат, консервируют, используют для приготовления банановои муки, мармелада, сиропов, вин. Бананы применяются также в качестве корма для скота. Запах бананов определяют изовалерианово-изоамиловыи и уксусно-изоамиловыи эфиры. Выращиваются в тропических и субтропических раионах с жарким влажным климатом. Существует большое число сортов съедобных видов банана.\n",
      "Размер, цвет и форма могут значительно различаться в зависимости от вида или сорта, но чаще всего они имеют продолговатую цилиндрическую или трехгранную форму, выпрямленную либо закругленную. Длина плода варьирует в пределах от 3 до 40 см, толщина — от 2 до 8 см. Цвет кожицы может быть желтым, зеленым, красным или даже серебристым. Мякоть белая, кремовая, желтая или оранжевая. В незрелом состоянии она твердая и клеикая, но по мере созревания становится мягкои и сочнои.\n",
      "Во многих странах бананы являются одним из основных источников питания — например, только в Эквадоре годовое потребление этого продукта составляет 73,8 кг на душу населения (для сравнения, в России этот показатель равен 7,29 кг). Существенную долю потребления бананы также составляют в Бурунди (189,4 кг), Самоа (85,0 кг), Коморских Островах (77,8 кг) и на Филиппинах (40,6 кг).\n",
      "['банан', '—', 'название', 'съедобных', 'плодов']\n"
     ]
    }
   ],
   "source": [
    "get_hyperonyms(\"банан\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 (deadline 19.02.2020 24:00)\n",
    "* Find your name on the spreadsheet https://docs.google.com/spreadsheets/d/1RR2I6toCkebbGU1UK83HS70Ru_l0_o-nnZIHyiFB0No/edit?usp=sharing. In opposite of your name there are 24 words of hyponyms, you have to insert five corresponding hypernyms next to them. Examples of hyponyms and hyperonyms relationship you can find above in the current Jupiter notebook.\n",
    "* Find for each pair of hyponyms and hypernyms a corresponding snippet of a text with their mentions. The source of the text can be any free resources, e.g., Wikipedia, Google, Yandex, others. You should save the snippets and their URLs within the lab2 folder in your NLP git-repo with .csv file-extension in a single file.\n",
    "\n",
    "#### Task 2 (deadline 26.02.2020 24:00)\n",
    "* It would be best if you created a pandas DataFrame of the texts from the previous task. And apply to the DataFrame the function 'get_hyperonyms,' which must return the list of the corresponding hypernyms from the text automatically. If there are errors or misses, you should fix them in the code for your case of the 24 words. Nevertheless, it is strictly prohibited to use hard coding. Save your notebook with parser code within the lab2 folder in your NLP git-repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HYPONYM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>РИГЕЛЬ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>РИЗНИЦА</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>РИЗОТТО</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>РИККЕТСИЯ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>РИСЛИНГ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HYPONYM\n",
       "0     РИГЕЛЬ\n",
       "1    РИЗНИЦА\n",
       "2    РИЗОТТО\n",
       "3  РИККЕТСИЯ\n",
       "4    РИСЛИНГ"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('word.xlsx')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in list(data['Hu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гиперонимы для слова:  РИГЕЛЬ\n",
      "\n",
      "\n",
      "Ригель — яркая околоэкваториальная звезда, β Ориона. Бело-голубои сверхгигант. Название по-арабски значит «нога» (имеется в виду нога Ориона). Имеет визуальную звездную величину 0,12m. Ригель находится на расстоянии примерно 860 световых лет от Солнца. Температура его поверхности 12 130 К (спектральныи класс B8I-a), диаметр около 103 млн км (то есть в 74 раза больше Солнца) а абсолютная звездная величина −7,84m; его светимость примерно в 130 000 раз выше солнечнои, а значит, это одна из самых мощных звезд в Галактике (во всяком случае, наряду с Денебом, одна из двух самых мощных ярчаиших звезд на небе, так как Ригель — ближаишая из звезд с такои огромнои светимостью).\n",
      "Древние египтяне связывали Ригель с Сахом — царем звезд и покровителем умерших, а позже — с Осирисом.\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  РИЗНИЦА\n",
      "\n",
      "\n",
      "Ризница (ризохранилище) — место в алтаре или отдельное помещение при христианском храме для хранения богослужебного облачения священников (прежде всего, риз) и церковнои утвари (священных сосудов) — в целом, то же самое, что опистодом в египетском или античном храме.Духовное лицо, заведующее ризницеи, называется ризничим, а в кафедральных соборах — это соборныи ключарь.\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  РИЗОТТО\n",
      "\n",
      "\n",
      "Ризотто (итал. risotto, означает «маленькии рис») — блюдо итальянскои кухни из риса, с мягким, сливочным вкусом. Первое письменное упоминание о нем встречается только в XIX веке.\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  РИККЕТСИЯ\n",
      "\n",
      "\n",
      "Риккетсии (лат. Rickettsia) — род бактерии — внутриклеточных паразитов. Названы по имени Ховарда Теилора Риккетса (1871—1910), в 1909 году впервые описавшего возбудителя пятнистои лихорадки Скалистых гор. В том же году сходные наблюдения были сделаны Ш. Николем и его коллегами при исследовании сыпного тифа. В 1910 году Риккетс погиб от сыпного тифа, изучением которого занимался в Мексике. В честь заслуг ученого возбудители этих инфекции были названы «риккетсиями».\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  РИСЛИНГ\n",
      "\n",
      "\n",
      "Рислинг (нем. Riesling) — техническии (винныи) сорт винограда, используемыи для производства белых вин. По морфологическим признакам и биологическим своиствам Рислинг относится к эколого-географическои группе западноевропеиских сортов винограда. Культивируется во многих странах мира — в основном, Германии, Австрии, Франции (регион Эльзас) и Австралии, а также в России, Болгарии, Венгрии, Швеицарии, США, Аргентине и др. странах.\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  РИСОВОД\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "PageError",
     "evalue": "Page id \"рисовая\" does not match any pages. Try another id!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPageError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-9923d557b74e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Гиперонимы для слова: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mget_hyperonyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-f5646b675834>\u001b[0m in \u001b[0;36mget_hyperonyms\u001b[0;34m(main_word)\u001b[0m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRULE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeaccent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\(.+?\\)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/wikipedia/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(title, sentences, chars, auto_suggest, redirect)\u001b[0m\n\u001b[1;32m    229\u001b[0m   \u001b[0;31m# use auto_suggest and redirect to get the correct article\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m   \u001b[0;31m# also, use page's error checking to raise DisambiguationError if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m   \u001b[0mpage_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_suggest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto_suggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m   \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0mpageid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpageid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36mpage\u001b[0;34m(title, pageid, auto_suggest, redirect, preload)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m# if there is no suggestion or search results, the page doesn't exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mPageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mWikipediaPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mpageid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mWikipediaPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpageid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpageid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, title, pageid, redirect, preload, original_title)\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Either a title or a pageid must be specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self, redirect, preload)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'missing'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mPageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mPageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpageid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpageid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPageError\u001b[0m: Page id \"рисовая\" does not match any pages. Try another id!"
     ]
    }
   ],
   "source": [
    "for word in list(data['HYPONYM']):\n",
    "    print('Гиперонимы для слова: ', word)\n",
    "    print('\\n')\n",
    "    get_hyperonyms(word)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
