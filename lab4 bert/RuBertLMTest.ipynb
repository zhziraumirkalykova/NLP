{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, BertPreTrainedModel, BertForPreTraining, BertForMaskedLM\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os\n",
    "RUBERT_PATH = '/Users/zhazira/Documents/masters/nlp2020/lab4 bert/rubert_cased_L-12_H-768_A-12_pt'\n",
    "modelpath = os.path.join(RUBERT_PATH,'pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(os.path.join(RUBERT_PATH,'pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=119547, bias=True)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained(os.path.join(RUBERT_PATH,'vocab.txt'))\n",
    "tokenizer = BertTokenizer.from_pretrained(RUBERT_PATH, do_lower_case=False)\n",
    "config = BertConfig.from_json_file(os.path.join(RUBERT_PATH,'bert_config.json'))\n",
    "model = BertForPreTraining.from_pretrained(modelpath, config=config)\n",
    "# model.eval()\n",
    "# model = BertForMaskedLM.from_pretrained(modelpath, config=config)\n",
    "model.eval()\n",
    "\n",
    "# model = BertForPreTraining.from_pretrained(RUBERT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Пасс', '##иона', '##́ри', '##и', '—', 'в', 'пасс', '##иона', 'р', '##ной', 'теории', 'этноген', '##еза', 'люди', ',', 'обладающие', 'врожд', '##ённой', 'способностью', 'абсорб', '##ировать', 'из', 'внешней', 'среды', 'энергии', 'больше', ',', 'чем', 'это', 'требуется', 'только', 'для', 'личного', 'и', 'видов', '##ого', 'самос', '##охран', '##ения', ',', 'и', 'выдавать', 'эту', 'энергию', 'в', 'виде', 'целенаправленно', '##й', 'работы', 'по', 'видоизмен', '##ению', 'окружающей', 'их', 'среды', '.', 'Судя', '##т', 'о', 'повышенной', 'пасс', '##иона', '##р', '##ности', 'того', 'или', 'иного', 'человека', 'по', 'характеристике', 'его', 'поведения', 'и', 'психики', '.']\n",
      "73\n",
      "torch.Size([1, 75])\n",
      "tensor([[ 56493,   9042, 114177,    852,    901,    845,  32038,   9042,    873,\n",
      "           1700,  14422,  99221,  16182,  11894,    128,  62824,  47474,  11827,\n",
      "          38843,  81836,   7996,   1703,  20895,  18624,  17754,   8980,    128,\n",
      "           3622,   3998,  23145,   4564,   2748,  23332,    851,  11587,   1636,\n",
      "          41206,   9226,   1757,    128,    851,  45571,  11204,  32851,    845,\n",
      "           7310,  89196,    860,   7089,   1516,  55611,   3516,  21615,   3806,\n",
      "          18624,    132,  38522,    868,    612,  33817,  32038,   9042,    874,\n",
      "           2825,   4105,   3474,  34984,   6798,   1516,  95748,   2752,  24494,\n",
      "            851,    103,    132]])\n",
      "torch.Size([1, 75, 119547])\n",
      "Original: Пассиона́рии — в пассиона рной теории этногенеза люди, обладающие врождённой способностью абсорбировать из внешней среды энергии больше, чем это требуется только для личного и видового самосохранения, и выдавать эту энергию в виде целенаправленной работы по видоизменению окружающей их среды. Судят о повышенной пассионарности того или иного человека по характеристике его поведения и психики.\n",
      "Masked: Пасс ##иона ##́ри ##и — в пасс ##иона р ##ной теории этноген ##еза люди , обладающие врожд ##ённой способностью абсорб ##ировать из внешней среды энергии больше , чем это требуется только для личного и видов ##ого самос ##охран ##ения , и выдавать эту энергию в виде целенаправленно ##й работы по видоизмен ##ению окружающей их среды . Судя ##т о повышенной пасс ##иона ##р ##ности того или иного человека по характеристике его поведения и [MASK] .\n",
      "torch.Size([1, 75, 119547])\n",
      "Predicted token: ['др']\n",
      "Other options:\n",
      "10776\n",
      "['др']\n",
      "10776\n",
      "['др']\n",
      "10776\n",
      "['др']\n",
      "10776\n",
      "['др']\n",
      "10776\n",
      "['др']\n",
      "10776\n",
      "['др']\n",
      "10776\n",
      "['др']\n",
      "10776\n",
      "['др']\n",
      "10776\n",
      "['др']\n",
      "10776\n",
      "['др']\n"
     ]
    }
   ],
   "source": [
    "text = u\"Пассиона́рии — в пассиона рной теории этногенеза люди, обладающие врождённой способностью абсорбировать из внешней среды энергии больше, чем это требуется только для личного и видового самосохранения, и выдавать эту энергию в виде целенаправленной работы по видоизменению окружающей их среды. Судят о повышенной пассионарности того или иного человека по характеристике его поведения и психики.\"\n",
    "target = u\"психики\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(tokenized_text)\n",
    "# Mask a token that we will try to predict back with `BertForMaskedLM`\n",
    "masked_index = tokenized_text.index(target)\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "print(masked_index)\n",
    "\n",
    "# Convert token to vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "# this is for the dummy first sentence. \n",
    "segments_ids[0] = 0\n",
    "segments_ids[1] = 0\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "print(tokens_tensor.shape)\n",
    "print(tokens_tensor)\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "# Load pre-trained model (weights)\n",
    "# model = BertForMaskedLM.from_pretrained(modelpath)\n",
    "# model.eval()\n",
    "\n",
    "# Predict all tokens\n",
    "predictions = model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "print(predictions[0].shape)\n",
    "predicted_index = torch.argmax(predictions[0][0][masked_index]).item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])\n",
    "print(\"Original:\", text)\n",
    "print(\"Masked:\", \" \".join(tokenized_text))\n",
    "print(predictions[0].shape)\n",
    "print(\"Predicted token:\", predicted_token)\n",
    "print(\"Other options:\")\n",
    "# just curious about what the next few options look like.\n",
    "for i in range(10):\n",
    "#     predictions[0,masked_index,predicted_index] = -11100000\n",
    "    predicted_index = torch.argmax(predictions[0][0][masked_index]).item()\n",
    "    print(predicted_index)\n",
    "    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])\n",
    "    print(predicted_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.OrderedDict'>\n"
     ]
    }
   ],
   "source": [
    "from torch import load\n",
    "di = load(modelpath)\n",
    "# with open(modelpath,encoding='utf-8') as fh:\n",
    "print(type(di))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Сериал очень люблю, но Академия и Земля вызыва...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>думал, что будет лучше идея очень интересна - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>с творчеством Головачева я познакомился посред...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>то-то я и в большое неудовольствие прочитал \"А...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>как мне показалось местами сильно смахивает на...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Сериал очень люблю, но Академия и Земля вызыва...\n",
       "1  думал, что будет лучше идея очень интересна - ...\n",
       "2  с творчеством Головачева я познакомился посред...\n",
       "3  то-то я и в большое неудовольствие прочитал \"А...\n",
       "4  как мне показалось местами сильно смахивает на..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#texts data\n",
    "texts_df = pd.read_csv('texts_train.txt', sep=\"\\t\", header=None)\n",
    "texts_df.columns = [\"text\"]\n",
    "texts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tonality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Сериал очень люблю, но Академия и Земля вызыва...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>думал, что будет лучше идея очень интересна - ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>с творчеством Головачева я познакомился посред...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>то-то я и в большое неудовольствие прочитал \"А...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>как мне показалось местами сильно смахивает на...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tonality\n",
       "0  Сериал очень люблю, но Академия и Земля вызыва...         6\n",
       "1  думал, что будет лучше идея очень интересна - ...         7\n",
       "2  с творчеством Головачева я познакомился посред...        10\n",
       "3  то-то я и в большое неудовольствие прочитал \"А...         5\n",
       "4  как мне показалось местами сильно смахивает на...         6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#texts data\n",
    "texts_df = pd.read_csv('dataset1000.csv', sep=\",\")\n",
    "texts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "\n",
    "def get_means(sentence):\n",
    "    tokenized_text = tokenizer.tokenize(sentence)\n",
    "    tokenized_text = tokenized_text[:max_input_length-2]\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    \n",
    "    segments_ids = [1] * len(tokenized_text)    \n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    predictions = model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "    _, secondDims, thirdDims = predictions[0].shape\n",
    "    \n",
    "    finalVector = []\n",
    "    \n",
    "    for i in range(secondDims):\n",
    "        currentArr = predictions[0][0][i].detach().numpy()\n",
    "        if len(finalVector) == 0:\n",
    "            finalVector = currentArr\n",
    "        else:\n",
    "            finalVector = np.add(finalVector, currentArr)\n",
    "    return np.mean(finalVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-213.32309"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_means(texts_df['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       6\n",
       "1       7\n",
       "2      10\n",
       "3       5\n",
       "4       6\n",
       "       ..\n",
       "994     9\n",
       "995     9\n",
       "996     6\n",
       "997     4\n",
       "998     9\n",
       "Name: tonality, Length: 999, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df[\"tonality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile('vectors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tonality</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-213.323090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-95.984756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-279.542175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-155.725052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-251.803604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tonality      vector\n",
       "0       NaN -213.323090\n",
       "1       NaN  -95.984756\n",
       "2       NaN -279.542175\n",
       "3       NaN -155.725052\n",
       "4       NaN -251.803604"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.read_csv('vectors.csv', dtype='float64')\n",
    "vector = [get_means(sentence) for sentence in texts_df[\"text\"].tolist()]\n",
    "scores_df['vector'] = vector\n",
    "\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df['tonality'] = texts_df[\"tonality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tonality</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-213.323090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-95.984756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>-279.542175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>-155.725052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>-251.803604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tonality      vector\n",
       "0         6 -213.323090\n",
       "1         7  -95.984756\n",
       "2        10 -279.542175\n",
       "3         5 -155.725052\n",
       "4         6 -251.803604"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.to_csv('.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tonality = np.array(scores_df['tonality'])\n",
    "vector = np.array(scores_df['vector']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(tonality, vector, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "regressor = RandomForestClassifier(n_estimators=2000, random_state=0)\n",
    "R = regressor.fit(X_train, y_train)\n",
    "Y_predict = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9,  9,  6,  8,  2, 10, 10,  9, 10,  7,  9,  7,  9, 10, 10,  7, 10,\n",
       "        9,  1,  5,  9,  9,  9,  7,  8,  9,  1, 10,  9,  9,  9,  9,  9, 10,\n",
       "        8,  6,  6, 10,  7, 10,  7, 10,  9,  9, 10,  9, 10,  8,  9,  9,  9,\n",
       "        4,  7,  9,  9,  9,  8,  8,  9,  9,  9,  9, 10,  8, 10,  3, 10,  9,\n",
       "       10,  9,  7,  5,  5, 10, 10,  9, 10,  9,  7,  7,  9,  8, 10,  8,  6,\n",
       "       10,  8, 10,  9, 10,  8,  7, 10,  8,  4,  8,  1, 10,  8,  9,  9, 10,\n",
       "       10,  9,  8,  8,  9,  9, 10,  9,  9, 10,  2, 10,  9,  8, 10, 10,  9,\n",
       "       10,  3,  9,  9,  9,  9, 10,  9, 10,  8, 10,  7,  9,  8,  9,  9,  6,\n",
       "        7, 10,  8, 10, 10,  8,  7,  8,  8, 10,  4, 10, 10,  9,  9, 10,  8,\n",
       "        3,  8,  9,  9, 10,  9, 10,  6,  8, 10,  9,  9,  8, 10, 10,  8,  4,\n",
       "        9, 10,  8,  7,  7,  7,  5,  5,  9,  9,  6,  9, 10, 10,  9,  7,  9,\n",
       "        9,  9, 10,  3,  9, 10,  9, 10, 10, 10,  9, 10, 10])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  1, 10,  8,  9,  9, 10, 10,  4,  8,  4,  5, 10, 10,  1,  3,  8,\n",
       "       10,  7,  9,  9,  9,  9,  7,  9, 10, 10,  7,  7, 10,  9,  9, 10, 10,\n",
       "        9,  4,  6, 10, 10,  8,  8,  8,  7,  7, 10, 10, 10,  8,  8,  8,  1,\n",
       "        6, 10,  9,  7,  8, 10, 10,  9,  9, 10,  7,  3,  8,  9, 10,  6,  9,\n",
       "        8, 10,  8,  7,  9,  9,  8,  9,  9,  9,  9,  8,  8,  8,  4, 10,  7,\n",
       "        9, 10,  1, 10,  6, 10, 10,  8, 10,  6,  8,  9, 10,  9, 10,  8,  9,\n",
       "       10,  3,  9,  9,  9,  9, 10, 10, 10,  7,  7, 10,  9,  7,  9,  9, 10,\n",
       "        9,  6,  2,  7, 10, 10,  9,  6,  3,  7,  9,  8,  9,  8, 10,  7,  9,\n",
       "        8, 10,  8,  9,  8,  9,  9,  5,  8,  8, 10,  9,  8, 10, 10,  9,  9,\n",
       "        8,  9, 10,  7,  8, 10,  4,  9, 10, 10,  4,  9, 10, 10,  7,  8,  9,\n",
       "        9,  9, 10,  8,  8,  9,  8,  8,  3, 10, 10, 10, 10,  9,  1,  9,  9,\n",
       "        8,  2, 10,  4,  8, 10,  1, 10,  9,  8, 10, 10,  6])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.235"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, Y_predict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[ 0  0  0  0  0  0  1  0  1  1]\n",
      " [ 0  0  0  0  0  0  1  0  1  0]\n",
      " [ 0  0  0  1  0  1  0  1  0  1]\n",
      " [ 0  0  0  0  0  2  0  0  1  1]\n",
      " [ 0  0  0  0  0  0  1  2  2  0]\n",
      " [ 0  0  0  1  0  1  1  0  2  2]\n",
      " [ 0  0  1  0  1  0  1  8  4  3]\n",
      " [ 0  0  0  0  1  0  2  9  8  9]\n",
      " [ 4  2  2  2  0  1  8  8 18 24]\n",
      " [ 2  0  2  3  0  3  3 11 17 18]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.12      0.14      0.13         7\n",
      "           7       0.06      0.06      0.06        18\n",
      "           8       0.23      0.31      0.26        29\n",
      "           9       0.33      0.26      0.29        69\n",
      "          10       0.31      0.31      0.31        59\n",
      "\n",
      "    accuracy                           0.23       200\n",
      "   macro avg       0.10      0.11      0.11       200\n",
      "weighted avg       0.25      0.23      0.24       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = confusion_matrix(y_test, Y_predict) \n",
    "print('Confusion Matrix :')\n",
    "print(results)\n",
    "print('Report : ')\n",
    "print(classification_report(y_test, Y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(Y_predict, test):\n",
    "    errors = abs(Y_predict - test)\n",
    "    accuracy = 100 - np.mean(100 * (errors / test))\n",
    "    print('Accuracy:', round(accuracy, 2), '%.')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.68 %.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61.67876984126984"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(Y_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
